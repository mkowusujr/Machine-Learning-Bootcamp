{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "+ Pandas is an open source library built on top of NumPy\n",
    "+ It allows for fast analysis and data cleaning and preparation\n",
    "+ It excels in performance and productivity'It has built-in visualization features\n",
    "+ It can work with data from a wide variety of sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series\n",
    "A series is similar to a numpy array, it is built on top numpy array object. What makes it different is that it can be indexed by a label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['a', 'b', 'c']\n",
    "my_data = [10, 20, 20]\n",
    "arr = np.array(my_data)\n",
    "dictionary = {'a':10, 'b':20, 'c':30}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(data=my_data) # By default series are index numerical\n",
    "pd.Series(data=my_data, index=labels) # setting custom indexs/labels\n",
    "pd.Series(arr) # creating series with np array\n",
    "pd.Series(dictionary) # creating series with a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grabbing Info From Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1 = pd.Series([1,2,3,4],['USA','Germany','USSR','Japan'])\n",
    "ser1['USA'] # returns value at the USA index\n",
    "ser1[0] # return value at the 0 index\n",
    "\n",
    "ser2 = pd.Series([1,2,5,4],['USA','Germany','Italy','Japan'])\n",
    "\n",
    "ser1 + ser2 # Operations on series are based on the index, if index doesn't exists it outputs NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrames\n",
    "DataFrames are a bunch of series that share an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import randn\n",
    "np.random.seed(101) # Makes sure the same random numbers are generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=randn(5,4), index=['A','B','C','D','E'], columns=['W', 'X', 'Y', 'Z'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting and Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['W'] # returns the W column which is a series\n",
    "type(df['W']) # returns the type\n",
    "\n",
    "df[['W', 'Z']] # returns multiple series in the form of a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creaing Columns, Dropping Columns, and Selecting Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['new'] = df['W'] + df['Z'] # Creating a new column\n",
    "\n",
    "df.drop('new', axis=1, inplace=True) # Deleting a column, to delete row set axis to 0, inplace needs to be set to true to save changes\n",
    "df.drop('E', inplace=True) # Deleting a row\n",
    "\n",
    "df.loc['A'] # Selecting the A row and retuns a series, selects with label index\n",
    "df.iloc[2] # selecting with numerical index\n",
    "df.loc['A', 'Y'] # Selects row and column\n",
    "df.loc[['A', 'B'], ['W','Y']]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df>0] # A DataFrame where all the values are greater than zero, NaN if there a false\n",
    "df[df['W']>0] # DataFrame where all the values in column W are greater than 0\n",
    "df[df['W']>0]['Y'] # We can chain df functions on conditional selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For two conditions you can use | and & with parenthesis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['W']>0) & (df['Y'] > 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Index Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index # Reset index to default 0,1...n\n",
    "\n",
    "new_index = 'CA NY WY OR CO'.split()\n",
    "df['States'] = new_index # New column\n",
    "df.set_index('States', inplace=True) # Setting a column to be the new index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Index and Index Hierachy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up multi-level indexes\n",
    "outside = ['G1','G1','G1','G2','G2','G2']\n",
    "inside = [1,2,3,1,2,3]\n",
    "hier_index = list(zip(outside,inside))\n",
    "hier_index = pd.MultiIndex.from_tuples(hier_index)\n",
    "df = pd.DataFrame(np.random.randn(6,2),index=hier_index,columns=['A','B'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['G1'] # Selects the rows in the G1 index\n",
    "df.loc['G1'].loc[1] # Selects row 1 in the G1 index\n",
    "\n",
    "df.index.names = ['Group', 'Num'] # Naming our columns\n",
    "df.index.names\n",
    "\n",
    "df.xs('G1') # Selects the rows in the G1 index\n",
    "df.xs(['G1', 1]) # Selects row 1 in the G1 index\n",
    "df.xs(1, level='Num') # Selects all the row 1's from the Num index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A':[1,2,np.nan],\n",
    "                   'B':[5,np.nan,np.nan],\n",
    "                   'C':[1,2,3]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember you need the inplace=True argument to do the operation in place\n",
    "df.dropna() # Drop all the rows with NaN\n",
    "df.dropna(axis=1) # Drop all the columns with NaN\n",
    "df.dropna(thresh=2) # Require that many non-NA values per row\n",
    "df.fillna(value='FILL VALUE') # Replace all the NaN values with the given value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GroupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Company':['GOOG','GOOG','MSFT','MSFT','FB','FB'],\n",
    "       'Person':['Sam','Charlie','Amy','Vanessa','Carl','Sarah'],\n",
    "       'Sales':[200,120,340,124,243,350]}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_comp = df.groupby(\"Company\") # Created a GroupBy object, these values become like an index\n",
    "by_comp.mean() # Returns the mean of all the values in each row belong to a index in the Company\n",
    "by_comp.std()\n",
    "by_comp.min()\n",
    "by_comp.max()\n",
    "by_comp.count()\n",
    "by_comp.describe()\n",
    "by_comp.describe().transpose()\n",
    "by_comp.describe().transpose()['GOOG'] # Describes just the GOOG index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging, Joining, and Concatenating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenation\n",
    "Concatenation basically glues together DataFrames. Keep in mind that dimensions should match along the axis you are concatenating on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                    'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "                    'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                    'D': ['D0', 'D1', 'D2', 'D3']},\n",
    "                    index=[0, 1, 2, 3])\n",
    "\n",
    "df2 = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'],\n",
    "                    'B': ['B4', 'B5', 'B6', 'B7'],\n",
    "                    'C': ['C4', 'C5', 'C6', 'C7'],\n",
    "                    'D': ['D4', 'D5', 'D6', 'D7']},\n",
    "                    index=[4, 5, 6, 7])\n",
    "\n",
    "pd.concat([df1,df2]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging\n",
    "\n",
    "The **merge** function allows you to merge DataFrames together using a similar logic as merging SQL Tables together. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\n",
    "                       'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                       'B': ['B0', 'B1', 'B2', 'B3']})\n",
    "   \n",
    "right = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\n",
    "                        'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                        'D': ['D0', 'D1', 'D2', 'D3']})    \n",
    "\n",
    "pd.merge(left,right,how='inner',on='key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining\n",
    "Joining is a convenient method for combining the columns of two potentially differently-indexed DataFrames into a single result DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = pd.DataFrame({'A': ['A0', 'A1', 'A2'],\n",
    "                     'B': ['B0', 'B1', 'B2']},\n",
    "                      index=['K0', 'K1', 'K2']) \n",
    "\n",
    "right = pd.DataFrame({'C': ['C0', 'C2', 'C3'],\n",
    "                      'D': ['D0', 'D2', 'D3']},\n",
    "                      index=['K0', 'K2', 'K3'])\n",
    "\n",
    "left.join(right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations\n",
    "There are lots of operations with pandas that will be really useful to you, but don't fall into any distinct category. Let's show them here in this lecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'col1':[1,2,3,4],'col2':[444,555,666,444],'col3':['abc','def','ghi','xyz']})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col2'].unique() # Returns an array of all the new unique values\n",
    "df['col2'].nunique() # Returns the number of new unique values\n",
    "df['col2'].value_counts() # Returns the number of unqiue values in each column\n",
    "\n",
    "newdf = df[(df['col1']>2) & (df['col2']==444)] # Select from DataFrame using criteria from multiple columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def times2(x):\n",
    "    return x*2\n",
    "\n",
    "df['col1'].apply(times2) # Multiplies all the values in col1 by two\n",
    "df['col2'].apply(lambda x: x * 2) # Lamda expression\n",
    "\n",
    "df['col3'].apply(len) # Len of each value in col3\n",
    "df['col1'].sum() # Sum of all values in col1\n",
    "\n",
    "del df['col1'] # permantly removing a column\n",
    "\n",
    "df.columns # get column na,es\n",
    "df.index # get indexes\n",
    "\n",
    "df.sort_values(by='col2', inplace=False) # Sort the DataFrame by the values in col2\n",
    "\n",
    "df.isnull() # Find all the null values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Input and Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('example') # CSV Input\n",
    "df.to_csv('example',index=False) # CSV Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excel\n",
    "Pandas can read and write excel files, keep in mind, this only imports data. Not formulas or images, having images or macros may cause this read_excel method to crash. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_excel('Excel_Sample.xlsx',sheetname='Sheet1') # Excel Input\n",
    "df.to_excel('Excel_Sample.xlsx',sheet_name='Sheet1') # Excel Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML\n",
    "\n",
    "You may need to install htmllib5,lxml, and BeautifulSoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for all the table elements and returns them as a list of dataframes\n",
    "df = pd.read_html('http://www.fdic.gov/bank/individual/failed/banklist.html')\n",
    "df[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///:memory:') # Establishing a connection\n",
    "\n",
    "df.to_sql('data', engine) # Output to sql tables\n",
    "sql_df = pd.read_sql('data',con=engine) # Input from Sql table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b3bf6ed06d97df9215025b9c2a41885c4e82cb7758b47c012e2fa2978dd3e5b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
